# Overall Response

We would like to express our sincere gratitude for the constructive feedback received from the reviewers. 
We will carefully address the points raised and implement the necessary changes to our paper.

First, we address the efficiency of our lazy normalization approach. 
The classical algorithm performs a full traversal of the coalgebra during liveness checking before bisimulation. 
In contrast, our algorithm invokes bisimulation and only traverses the reachable states of the discrepancies. 
This change results in fewer states being traversed during liveness checking, even for positive results. 
Additionally, lazy liveness checking enables on-the-fly coalgebra generation using methods like derivatives, which the original algorithm does not support.

Second, we address the theoretical contribution of our work. 
While our algorithm may seem intuitive, our proof is not trivial. 
Directly connecting the algorithm with bisimulation on the normalized coalgebra, as in Theorem 21, is challenging; partially because we do not assume that the input coalgebra or bisimulation are finite.
We have reworked the framework several times to pin-down the concise notion of "greedy bisimulation", leading to modular results that build up to the final correctness result. 
The effectiveness of greedy bisimulation as a theoretical tool is demonstrated by the generality of our result, and the simplicity of most proofs, which are either unfoldings of definitions or standard exercises in coalgebra.

Finally, we emphasize that our contribution extends beyond bisimulation of coalgebras (or machines).
In Section V, we present two methods for generating coalgebras from expressions and prove their correctness, finiteness, and correspondence. 
The finiteness result elegantly arises from the correspondence result, a point noted by one of the reviewers.

Regarding experiments in our work, We have reworked our test cases, removing all "trivial" or dead test cases. 
Evidently, our performance is minimally impacted by the new test cases. 
By analyzing the algorithm, we can see that "trivial" tests do not provide any performance benefit for the algorithm based on Thompson's construction, and dead test cases do not favor our algorithms against other tools.

# Reviewer Questions

### Reviewer 1

> Where are the benchmarks from?

Benchmarks are generated by https://github.com/c-cube/qcheck, based on congruence, symmetry, and some algebraic rules of GKAT (excluding rules that will be "trivial" tests, as named by Reviewer 3).
We will include the generation script in the final submission, and provide documentation on test generation

> Unnecessary but harmful generalization

We will specify in the background section that we assume the function `F` to be simple polynomial functors.

### Reviewer 2

Our approach to symbolic transducers diverges from previous works in several key aspects:
- Our on-the-fly method is tailored to handle normalization, a unique challenge in achieving finite trace equivalence for GKAT. 
- The signature of GKAT differs from traditional symbolic transducers. Unlike typical accepting or rejecting states, a GKAT state can accept or reject based on different input atoms. This results in a distinct semantics where a trace's end is marked by an atom, representing the output program state.
In general, we feel our work is a novel contribution, independent of the prior works on symbolic transducers or symbolic coalgebra.

While symbolic algorithm is pivotal for scaling our equivalence algorithm to more primitive tests, it is not our sole contribution. 
We have also developed:
- An on-the-fly algorithm for bisimulation, and proved its correctness using greedy bisimulation, a novel and clean coalgebra construction.
- Two distinct methods to construct symbolic GKAT coalgebras, while also proved their correctness, finiteness, and correspondence. 

# Detailed Response

### Reviewer 1

> why is it relevant to check whether two GKAT expressions are equivalent?

GKAT has been used in several important verification tasks for networks, control-flow transformation, probabilistic computation, and program logic.
We mentioned this fact at the end of the related work section. 
We will also mention the practical application of GKAT in the introduction section.

> it's unclear to me what section III is for if you have section IV

The correctness result of section IV is based on the correctness result in section III. 
Besides, there can be edge cases (depending on the application) where the number of primitive tests are so small that the algorithm in section III can potentially be more efficient. 
We will make sure that the structure of the paper is more evident in the introduction section and the first paragraph of each section.

### Reviewer 2

> there can still be dead states in a normalized coalgebra

As in all the works in GKAT, dead states are indeed preserved in the normalized coalgebra.
This approach allows the semantics of dead states to be defined in the standard manner, i.e. via the unique map into final coalgebra.
We will provide better explanations in the background sections.

> can you say a bit more about SymKAT and why it might perform worse

SymKAT is a symbolic equivalence checker for Kleene Algebra with Tests (KAT). 
Our algorithm is specialized for GKAT, leveraging its deterministic structure to produce smaller automata (coalgebras) and utilizing existing SAT solvers to resolve boolean equivalence and inequivalence. 
This work represents the first theoretical and practical demonstration that GKAT equivalence can be checked more efficiently than KAT by employing a specialized solver, as designed in this paper.
We will make the distinction and the contribution more clear in the final version.

> "least GKAT coalgebra" doesn't make sense. 

GKAT coalgebra is naturally ordered with sub-GKAT coalgebra relation; then the least GKAT coalgebra satisfying a certain property is a sub-GKAT coalgebra of all the GKAT coalgebra satisfying said property.
We will provide this definition after the definition of greedy bisimulation.
Note that we do not assume such GKAT coalgebra always exists for all properties, the existence and uniqueness of greedy bisimulation is proved later. 

> It should be least relation containing ~ and closed under the transition relation. 

This also would lead to the same coalgebra. 
Treating greedy bisimulation itself as a GKAT coalgebra allows us to reuse several prior results, like homomorphism preserves liveness.
In fact, we believe that showing the existence of such ~ showed also require a theorem similar to Lemma 15, and then use the fact that subsets of ~_d form a complete lattice.
The proof above is essentially the same as our existence proof.

> GKAT is a bit artificial

GKAT semantics is based on trace semantics, a standard semantics used in programming languages and control-flow analysis. 
As you noted, trace equivalence is a stronger equivalence than input-output equivalence. 
However, trace equivalence proves to be useful in various applications, as we detailed in the last paragraph of the related work section and in response to Reviewer 1.
In fact, we foresee that our works here can be adapted to these applications and greatly improve their performance.
We will add a sentence stating the relevant applications of GKAT in the introduction section.

> Overall, I didn't quite understand, do you need to use bisimulations, or could you have start states and just compare traces directly? 

The algebraic treatment of bisimulation should coincide with the normal automata theoretical intuition, at least in the finite case.
However, by treating (greedy) bisimulation as coalgebras, we are able to use theorems like homomorphism preserves liveness or the functoriality of normalization.
The coalgebraic treatment makes our proofs more modular, and each proof more concise and straightforward, which we thought LICS appreciates. 
We will more clearly detail that our approach serves as a different approach than the automata theoretical intuition, while generating similar algorithms.

> For on-the-fly generally, do you want to cite some earlier work, e.g. Fernandez and Mounier, CAV 1991?

As the core challenge of our on-the-fly algorithm is normalization, we see our work as orthogonal to the work of Fernandez and Mounier.
However, we see that them as valuable references. 
In the final version, we will provide comparison between their work and ours in the related works section.

### Reviewer 3

> Theorem 23 is true, but Theorem 23 is not the proper tool to justify the correctness of the algorithm as mentioned on p7c2

A union-find structure represents an equivalence relation. 
By employing union-find instead of a set of state pairs, our algorithm will effectively search for a greedy bisimulation that is also an equivalence relation. 
While the correctness of greedy bisimulation is established (Theorem 21), there is no inherent justification for why finding a greedy bisimulation that is also an equivalence relation is equivalent to finding just any greedy bisimulation. 
To address this, we will apply Theorem 23 to demonstrate that there exists a greedy bisimulation that is also an equivalence relation if and only if two states are trace equivalent.
We will add more detailed explanation of how Theorem 23 and 21 interacts with each other.

> p5c2 "This approach offers several benefits: first, the liveness detection is only called when necessary, thus unlikely to iterate through the entire coalgebra; second, the algorithm can short-circuit on a counter-example, finally [...]""
> -> The first two are the same benefit.

The first benefit stems from the laziness of our liveness checking algorithm, allowing us to iterate through fewer states in the classical algorithm (see overall response and the next comment).  
This benefit exists regardless of the result of the algorithm or the generation method of the coalgebra. 
The second benefit stems from the on-the-fly nature of our algorithm.
Specifically, while we encounter a counter-example while using derivative to generate the coalgebra on-the-fly, our algorithm can terminate without generating the rest of the coalgebra.
In contrast, the original algorithm requires the complete generation of the coalgebra in order to perform liveness checking first.
In the final version, we will provide more detail and examples for these two benefits.

> p7c2 "In the extreme case when the two input states are infinite-trace equivalent, the on-the-fly algorithm can even skip liveness checking entirely." 
> -> yes, but in that case the liveness analysis would be faster (linear instead of almost linear)

We are uncertain why the original algorithm might be faster in this specific case. 
Consider two bisimilar states (infinite-trace equivalent) in a GKAT coalgebra with no dead state. 
The classical algorithm would perform a liveness check, iterating through all the states; then proceed with bisimulation, iterating through all the states again. 
Our algorithm simply performs the bisimulation; because these two states are bisimilar, our algorithm will bypass the liveness check altogether.
Additionally, the main performance bottleneck of our algorithm would be boolean (in)equivalence checks.
These checks are present in both liveness checking and bisimulation, and overshadows the time spent to look up in a union-find structure in practice. 

> say somewhere that these are more Antimorov' partial derivatives than Brzozowski's derivatives

While we employ the power set in the signature of the symbolic GKAT coalgebra, our derivatives do not transition in a non-deterministic manner. 
Specifically, when given an GKAT expression and a (valid) boolean expression, derivative will deterministically transition to a GKAT expression.
In this sense, our notion of derivative is closer to Brzozowski style than that of Antimorov, which we will detail in the final version
